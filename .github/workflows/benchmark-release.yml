name: Benchmark Data Processing

on:
  workflow_call:
    inputs:
      APP_GIT_TAG:
        description: 'Git tag for release naming'
        required: true
        type: string
    outputs:
      ai_csv_path:
        description: 'Path to AI metrics CSV'
        value: ${{ jobs.process-data.outputs.ai_csv_path }}
      supplementary_csv_path:
        description: 'Path to supplementary metrics CSV'
        value: ${{ jobs.process-data.outputs.supplementary_csv_path }}
      markdown_path:
        description: 'Path to generated markdown'
        value: ${{ jobs.process-data.outputs.markdown_path }}

jobs:
  process-data:
    runs-on: ubuntu-latest
    
    outputs:
      ai_csv_path: ${{ steps.setup.outputs.ai_csv_path }}
      supplementary_csv_path: ${{ steps.setup.outputs.supplementary_csv_path }}
      markdown_path: ${{ steps.setup.outputs.markdown_path }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'
      
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
      
      - name: Setup Paths
        id: setup
        run: |
          echo "ai_csv_path=results/reports/ai-metrics.csv" >> $GITHUB_OUTPUT
          echo "supplementary_csv_path=results/reports/supplementary-metrics.csv" >> $GITHUB_OUTPUT
          echo "markdown_path=results/reports/latest-benchmark-results.md" >> $GITHUB_OUTPUT
      
      - name: Create Initial Setup (if needed)
        run: |
          # Check if any release exists by counting lines of output from 'list'
          RELEASE_EXISTS=$(gh release list --limit 1 | wc -l)

          if [ "$RELEASE_EXISTS" -gt 0 ]; then
            echo "âœ… Releases already exist, downloading them"
            
            # Download existing releases
            python scripts/download_benchmark_data.py \
              --repo-owner "EAexist" \
              --repo-name "subscription-killer-api-benchmark" \
              --output-dir "results/reports"
          else
            echo "ðŸ“­ No releases found, creating results/reports from template files..."
            
            # Create results/reports directory
            mkdir -p results/reports
            
            # Copy template files to results/reports
            cp results/templates/ai-metrics.csv results/reports/
            cp results/templates/supplementary-metrics.csv results/reports/
            
            echo "âœ… Created results/reports directory with template files"
          fi
      
      - name: Process CSV Data
        run: |
          python scripts/benchmarkUtils.py \
            --existing-report "results/ai-benchmark" \
            --commit "${{ inputs.APP_GIT_TAG }}" \
            --dir "results/ai-benchmark/${{ inputs.APP_GIT_TAG }}"
      
      - name: Generate Markdown
        env:
          GEMINI_3_FLASH_PREVIEW_INPUT_TOKEN_PRICE_PER_MILLION: ${{ vars.GEMINI_INPUT_TOKEN_PRICE }}
          GEMINI_3_FLASH_PREVIEW_OUTPUT_TOKEN_PRICE_PER_MILLION: ${{ vars.GEMINI_OUTPUT_TOKEN_PRICE }}
        run: |
          python scripts/markdownUtils.py \
            --ai-csv "${{ steps.setup.outputs.ai_csv_path }}" \
            --supplementary-csv "${{ steps.setup.outputs.supplementary_csv_path }}" \
            --existing-report "results/ai-benchmark" \
            --commits "${{ inputs.APP_GIT_TAG }}" \
            --dirs "results/ai-benchmark/${{ inputs.APP_GIT_TAG }}"

      - name: Display Results
        run: |
          echo "ðŸ“Š Displaying benchmark results..."
          echo "\`\`\`markdown" >> $GITHUB_STEP_SUMMARY
          cat "${{ steps.setup.outputs.markdown_path }}" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
      
      - name: Create GitHub Release with Benchmark Data
        uses: softprops/action-gh-release@v1
        with:
          files: |
            results/reports/ai-metrics.csv
            results/reports/supplementary-metrics.csv
            results/reports/latest-benchmark-results.md
          name: Benchmark Results - ${{ inputs.APP_GIT_TAG }}
          tag_name: benchmark-${{ inputs.APP_GIT_TAG }}
          body: |
            ## ðŸ“Š Benchmark Results
            
            **Commit:** ${{ inputs.APP_GIT_TAG }}
            **Date:** ${{ github.event.head_commit.timestamp }}
            
            This release contains the latest benchmark results including:
            - AI Cost metrics (CSV)
            - Supplementary performance indicators (CSV) 
            - Formatted markdown report (MD)
            
            ### ðŸ“ Files Included
            - `ai-metrics.csv` - AI token usage and cost data
            - `supplementary-metrics.csv` - Performance indicators data
            - `latest-benchmark-results.md` - Formatted markdown report
            
            ---
            *Generated automatically by GitHub Actions benchmark workflow*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Update README.md
        run: |
          # Create a temporary script to properly replace benchmark results
          cat > replace_benchmark.awk << 'EOF'
          BEGIN {
            in_benchmark_section = 0
            skip_content = 0
          }
          
          /<!-- BENCHMARK_RESULTS_START -->/ {
            in_benchmark_section = 1
            skip_content = 1
            print
            # Print the new benchmark content
            while ((getline line < "${{ steps.setup.outputs.markdown_path }}") > 0) {
              print line
            }
            close("${{ steps.setup.outputs.markdown_path }}")
            next
          }
          
          /<!-- BENCHMARK_RESULTS_END -->/ {
            if (in_benchmark_section && skip_content) {
              in_benchmark_section = 0
              skip_content = 0
            }
            print
            next
          }
          
          {
            if (!skip_content) {
              print
            }
          }
          EOF
          
          awk -f replace_benchmark.awk README.md > README.tmp && mv README.tmp README.md
          
          echo "âœ… README.md updated successfully"
